# GenerativeAdversialNetwork
GAN is a battle between two adversaries, the generator and the discrminator.
The generator tries to convert random noise into observations so that it can fool the discriminator into thinking that it comes from the original dataset. The discriminator tries to predict whether an observation is real or fake (generated by the generator).

The key in GAN training is how we alternate the training of the two networks so that the generator makes more realistic observations and fools the discriminator, and the discriminator maintains its quality in distinguishing between real and fake observations.

## The Discriminator
The discriminator predicts if an observation is real or fake. The architecture is the same as a normal supervised binary classification, where the real observations have a label of one and the generated ones have a label of zero, with binary cross-entropy as the loss function.

![the discriminator takes samples from the original dataset and samples generated by the generator](https://github.com/hafifi29/GenerativeAdversialNetwork/assets/89405591/99399c9f-1060-45f7-9712-c8c1ad23829f)


## The Generator
The input to the generator is a vector drawn from a multivariate standard normal distribution, and the output is an observation of the same size as an observation in the original training data. _If you studied autoencoders, you can think of the generator as the decoder part of the autoencoder._

The discriminator generates a score for each image that passes through it. The loss function for the generator is then simply the binary cross-entropy between these probabilities and a vector of ones.

![the generator takes the loss from the discriminator to update its own weigths.](https://github.com/hafifi29/GenerativeAdversialNetwork/assets/89405591/b420f783-7c83-4c2f-9e59-2a221c4a21a3)

